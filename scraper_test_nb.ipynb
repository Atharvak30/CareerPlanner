{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_linkedin_search_url(job_title, location, start=0):\n",
    "    \"\"\"\n",
    "    Constructs a properly formatted LinkedIn job search URL.\n",
    "\n",
    "    Args:\n",
    "        job_title: Job title to search for (e.g., \"Software Engineer\")\n",
    "        location: Location to search in (e.g., \"San Francisco, CA\" or \"remote\")\n",
    "        start: Pagination offset (0, 25, 50, etc.)\n",
    "\n",
    "    Returns:\n",
    "        Properly formatted and URL-encoded LinkedIn job search URL\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search\"\n",
    "\n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "        \"start\": start\n",
    "    }\n",
    "\n",
    "    query_string = urllib.parse.urlencode(params)\n",
    "    return f\"{base_url}?{query_string}\"\n",
    "\n",
    "\n",
    "def test_linkedin_connection(url):\n",
    "    \"\"\"\n",
    "    Tests HTTP connectivity to LinkedIn job search URL.\n",
    "\n",
    "    Args:\n",
    "        url: The URL to test\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (status_code, response_length)\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Referer\": \"https://www.linkedin.com/\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        return response.status_code, len(response.text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error connecting to LinkedIn: {e}\")\n",
    "        return None, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated URL: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data+Scientist&location=remote&start=0\n",
      "\n",
      "Status Code: 429\n",
      "Response Length: 24633 characters\n",
      "\n",
      "✗ Connection test failed - Status: 429, Length: 24633\n"
     ]
    }
   ],
   "source": [
    "url = build_linkedin_search_url(\"Data Scientist\", \"remote\")\n",
    "print(f\"Generated URL: {url}\\n\")\n",
    "\n",
    "status, length = test_linkedin_connection(url)\n",
    "\n",
    "if status:\n",
    "    print(f\"Status Code: {status}\")\n",
    "    print(f\"Response Length: {length} characters\")\n",
    "\n",
    "    # Verify expectations\n",
    "    if status == 200 and length > 1000:\n",
    "        print(\"\\n✓ Connection test passed!\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Connection test failed - Status: {status}, Length: {length}\")\n",
    "else:\n",
    "    print(\"✗ Connection failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job_cards(html_content):\n",
    "    \"\"\"\n",
    "    Parses LinkedIn job search HTML to extract job listings.\n",
    "    \n",
    "    Args:\n",
    "        html_content: HTML string from LinkedIn job search\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing job information\n",
    "    \"\"\"\n",
    "    jobs = []\n",
    "    \n",
    "    try:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Find all job card list items\n",
    "        job_cards = soup.find_all('li')\n",
    "        \n",
    "        for card in job_cards:\n",
    "            try:\n",
    "                # Extract job title\n",
    "                title_elem = card.find(class_='base-search-card__title')\n",
    "                job_title = title_elem.get_text(strip=True) if title_elem else \"N/A\"\n",
    "                \n",
    "                # Extract company name\n",
    "                company_elem = card.find(class_='base-search-card__subtitle')\n",
    "                company = company_elem.get_text(strip=True) if company_elem else \"N/A\"\n",
    "                \n",
    "                # Extract location\n",
    "                location_elem = card.find(class_='job-search-card__location')\n",
    "                location = location_elem.get_text(strip=True) if location_elem else \"N/A\"\n",
    "                \n",
    "                # Extract posted date\n",
    "                posted_elem = card.find(class_='job-search-card__listdate')\n",
    "                posted_ago = posted_elem.get_text(strip=True) if posted_elem else \"N/A\"\n",
    "                \n",
    "                # Extract job URL\n",
    "                link_elem = card.find('a', class_='base-card__full-link')\n",
    "                job_url = link_elem.get('href', 'N/A') if link_elem else \"N/A\"\n",
    "                \n",
    "                # Extract job ID from URL\n",
    "                job_id = None\n",
    "                if job_url != \"N/A\":\n",
    "                    match = re.search(r'/jobs/view/(\\d+)', job_url)\n",
    "                    if match:\n",
    "                        job_id = match.group(1)\n",
    "                \n",
    "                # Only add if we have at least a title and URL\n",
    "                if job_title != \"N/A\" and job_url != \"N/A\":\n",
    "                    jobs.append({\n",
    "                        'job_id': job_id,\n",
    "                        'job_title': job_title,\n",
    "                        'company': company,\n",
    "                        'location': location,\n",
    "                        'posted_ago': posted_ago,\n",
    "                        'job_url': job_url\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # Skip individual cards that fail to parse\n",
    "                print(f\"Warning: Failed to parse a job card: {e}\")\n",
    "                continue\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HTML content: {e}\")\n",
    "        return []\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_jobs(title: str):\n",
    "    # Test with real request: Fetch Software Engineer jobs in remote\n",
    "    test_url = build_linkedin_search_url(title, \"remote\")\n",
    "    print(f\"Fetching jobs from: {test_url}\\n\")\n",
    "\n",
    "    # Make the request\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Referer\": \"https://www.linkedin.com/\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(test_url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(f\"✓ Successfully fetched data (Status: {response.status_code})\\n\")\n",
    "            \n",
    "            # Parse the jobs\n",
    "            jobs = parse_job_cards(response.text)\n",
    "            \n",
    "            print(f\"Found {len(jobs)} jobs\\n\")\n",
    "            print(\"=\" * 80)\n",
    "            print(\"First 3 jobs:\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            for i, job in enumerate(jobs, 1):\n",
    "                print(f\"\\n{i}. {job['job_title']}\")\n",
    "                print(f\"   Company: {job['company']}\")\n",
    "                print(f\"   Location: {job['location']}\")\n",
    "                print(f\"   Posted: {job['posted_ago']}\")\n",
    "                print(f\"   Job ID: {job['job_id']}\")\n",
    "                print(f\"   URL: {job['job_url']}...\" if len(job['job_url']) > 80 else f\"   URL: {job['job_url']}\")\n",
    "                \n",
    "                try:\n",
    "                    # Verify job_url and job_id exist\n",
    "                    assert job['job_url'] is not None and job['job_url'] != \"N/A\", f\"Job {i} missing URL\"\n",
    "                    assert job['job_id'] is not None, f\"Job {i} missing ID\"\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"✓ All tests passed! All jobs have valid URLs and IDs.\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"✗ Failed to fetch data (Status: {response.status_code})\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error during test: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching jobs from: https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Machine+Learning+Engineer&location=remote&start=0\n",
      "\n",
      "✓ Successfully fetched data (Status: 200)\n",
      "\n",
      "Found 10 jobs\n",
      "\n",
      "================================================================================\n",
      "First 3 jobs:\n",
      "================================================================================\n",
      "\n",
      "1. Machine Learning Engineer\n",
      "   Company: Certara\n",
      "   Location: United States\n",
      "   Posted: 1 day ago\n",
      "   Job ID: None\n",
      "   URL: https://www.linkedin.com/jobs/view/machine-learning-engineer-at-certara-4304414415?position=1&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=0wuWxJ1ynu7nTRrPsP0ZHQ%3D%3D...\n",
      "\n",
      "2. Research Executive - Data Scientist\n",
      "   Company: Unilever\n",
      "   Location: Bengaluru, Karnataka, India\n",
      "   Posted: 2 days ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/research-executive-data-scientist-at-unilever-4315071495?position=2&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=DGIoeFrPZgXfyTwcKu9Z7g%3D%3D...\n",
      "\n",
      "3. Staff Data Scientist\n",
      "   Company: LinkedIn\n",
      "   Location: Bengaluru, Karnataka, India\n",
      "   Posted: 2 days ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/staff-data-scientist-at-linkedin-4315356677?position=3&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=WYw8ul0PgSVayI9EJgk3dA%3D%3D...\n",
      "\n",
      "4. Data Scientist/Senior Data Scientist - Gen AI (3 to 5 Years)\n",
      "   Company: Fractal\n",
      "   Location: Bengaluru, Karnataka, India\n",
      "   Posted: 1 day ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/data-scientist-senior-data-scientist-gen-ai-3-to-5-years-at-fractal-4206436028?position=4&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=neC2SY99RPMzAxvcYHVPlg%3D%3D...\n",
      "\n",
      "5. Software Engineer, AI Platform\n",
      "   Company: LinkedIn\n",
      "   Location: Mountain View, CA\n",
      "   Posted: 2 days ago\n",
      "   Job ID: None\n",
      "   URL: https://www.linkedin.com/jobs/view/software-engineer-ai-platform-at-linkedin-4315367413?position=5&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=WBiXD341mLVi%2B00BJqtYgQ%3D%3D...\n",
      "\n",
      "6. Machine Learning Engineer, New Grad\n",
      "   Company: Latinx in AI (LXAI)\n",
      "   Location: San Francisco, CA\n",
      "   Posted: 3 days ago\n",
      "   Job ID: None\n",
      "   URL: https://www.linkedin.com/jobs/view/machine-learning-engineer-new-grad-at-latinx-in-ai-lxai-4315057004?position=6&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=SzQfvU2IZJQIYhtxI4WRog%3D%3D...\n",
      "\n",
      "7. Data Scientist\n",
      "   Company: AB InBev GCC India\n",
      "   Location: Bengaluru, Karnataka, India\n",
      "   Posted: 3 days ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/data-scientist-at-ab-inbev-gcc-india-4314768291?position=7&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=RbP9U0lm9IHHPF7wCFfAkg%3D%3D...\n",
      "\n",
      "8. Senior Software Engineer, Machine Learning\n",
      "   Company: LinkedIn\n",
      "   Location: Bengaluru, Karnataka, India\n",
      "   Posted: 2 days ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/senior-software-engineer-machine-learning-at-linkedin-4315365484?position=8&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=l4z%2FMIeea%2BtpT9LBP6%2Btcg%3D%3D...\n",
      "\n",
      "9. Associate Software Engineer -Python/AI/ML\n",
      "   Company: Devsinc\n",
      "   Location: Lahore, Punjab, Pakistan\n",
      "   Posted: 1 day ago\n",
      "   Job ID: None\n",
      "   URL: https://pk.linkedin.com/jobs/view/associate-software-engineer-python-ai-ml-at-devsinc-4316354350?position=9&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=iN36vjcorGtjpXSBKMO5rA%3D%3D...\n",
      "\n",
      "10. Data Scientist\n",
      "   Company: Fusemachines\n",
      "   Location: Pune, Maharashtra, India\n",
      "   Posted: 3 days ago\n",
      "   Job ID: None\n",
      "   URL: https://in.linkedin.com/jobs/view/data-scientist-at-fusemachines-4315332577?position=10&pageNum=0&refId=grRwL11JXg2Z3NMNgrFjiw%3D%3D&trackingId=HU6fF3WFhPPJuKzO%2BOMmfA%3D%3D...\n",
      "\n",
      "================================================================================\n",
      "✓ All tests passed! All jobs have valid URLs and IDs.\n"
     ]
    }
   ],
   "source": [
    "fetch_jobs(\"Machine Learning Engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobStorage:\n",
    "    \"\"\"\n",
    "    In-memory storage for job data with description management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.jobs = []\n",
    "    \n",
    "    def add_jobs(self, job_list):\n",
    "        \"\"\"\n",
    "        Store jobs in internal list.\n",
    "        \n",
    "        Args:\n",
    "            job_list: List of job dictionaries\n",
    "        \"\"\"\n",
    "        for job in job_list:\n",
    "            # Ensure each job has a description field\n",
    "            if 'description' not in job:\n",
    "                job['description'] = None\n",
    "            self.jobs.append(job)\n",
    "    \n",
    "    def get_all_jobs(self):\n",
    "        \"\"\"\n",
    "        Return all stored jobs.\n",
    "        \n",
    "        Returns:\n",
    "            List of all job dictionaries\n",
    "        \"\"\"\n",
    "        return self.jobs\n",
    "    \n",
    "    def get_jobs_without_description(self):\n",
    "        \"\"\"\n",
    "        Return jobs where description is None.\n",
    "        \n",
    "        Returns:\n",
    "            List of jobs without descriptions\n",
    "        \"\"\"\n",
    "        return [job for job in self.jobs if job.get('description') is None]\n",
    "    \n",
    "    def update_job_description(self, job_id, description):\n",
    "        \"\"\"\n",
    "        Update specific job's description.\n",
    "        \n",
    "        Args:\n",
    "            job_id: Job ID to update\n",
    "            description: Description text to set\n",
    "        \"\"\"\n",
    "        for job in self.jobs:\n",
    "            if job.get('job_id') == job_id:\n",
    "                job['description'] = description\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"\n",
    "        Return statistics about stored jobs.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with job statistics\n",
    "        \"\"\"\n",
    "        total = len(self.jobs)\n",
    "        with_desc = sum(1 for job in self.jobs if job.get('description') and job.get('description') != \"ERROR\")\n",
    "        without_desc = sum(1 for job in self.jobs if job.get('description') is None)\n",
    "        errors = sum(1 for job in self.jobs if job.get('description') == \"ERROR\")\n",
    "        \n",
    "        return {\n",
    "            'total_jobs': total,\n",
    "            'jobs_with_descriptions': with_desc,\n",
    "            'jobs_without_descriptions': without_desc,\n",
    "            'jobs_with_errors': errors\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_job_description(job_url):\n",
    "    \"\"\"\n",
    "    Fetch job description from LinkedIn job URL.\n",
    "    \n",
    "    Args:\n",
    "        job_url: URL to the job posting\n",
    "    \n",
    "    Returns:\n",
    "        Job description text or None if fetch fails\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Referer\": \"https://www.linkedin.com/\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(job_url, headers=headers, timeout=10)\n",
    "        \n",
    "        print(response)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            print(\"nigga 2\")\n",
    "            # Try multiple possible selectors for job description\n",
    "            desc_elem = (\n",
    "                soup.find('div', class_='show-more-less-html__markup') or\n",
    "                soup.find('div', class_='description__text') or\n",
    "                soup.find('section', class_='description') or\n",
    "                soup.find('div', class_='description') or\n",
    "                soup.find('article',class_='jobs-description__container jobs-description__container--condensed') or \n",
    "                soup.find('div',class_='jobs-description__content jobs-description-content jobs-description__content--condensed') or\n",
    "                soup.find('div', class_=re.compile(r'^job_description'))\n",
    "\n",
    "            )\n",
    "\n",
    "            print(\"nigga\")\n",
    "            \n",
    "            if desc_elem:\n",
    "                return desc_elem\n",
    "                description = desc_elem.get_text(strip=True)\n",
    "                return description if description else None\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching description: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [999]>\n"
     ]
    }
   ],
   "source": [
    "desc = fetch_job_description('https://www.linkedin.com/jobs/view/data-scientist-data-analytics-%E2%80%93-customer-loyalty-marketing-at-circle-k-4316137579/?position=3&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=brKmbAor271tMuHOwExs2Q%3D%3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_descriptions(storage, delay=3):\n",
    "    \"\"\"\n",
    "    Fetch descriptions for all jobs without descriptions.\n",
    "    \n",
    "    Args:\n",
    "        storage: JobStorage instance\n",
    "        delay: Seconds to wait between requests (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        Count of successful fetches\n",
    "    \"\"\"\n",
    "    jobs_to_fetch = storage.get_jobs_without_description()\n",
    "    total = len(jobs_to_fetch)\n",
    "    successful = 0\n",
    "    \n",
    "    print(f\"Fetching descriptions for {total} jobs...\\n\")\n",
    "    \n",
    "    for i, job in enumerate(jobs_to_fetch, 1):\n",
    "        job_title = job.get('job_title', 'Unknown')\n",
    "        job_id = job.get('job_id')\n",
    "        job_url = job.get('job_url')\n",
    "        \n",
    "        print(f\"[{i}/{total}] Fetching description for: {job_title}...\")\n",
    "        \n",
    "        try:\n",
    "            description = fetch_job_description(job_url)\n",
    "            \n",
    "            if description:\n",
    "                storage.update_job_description(job_id, description)\n",
    "                successful += 1\n",
    "                print(f\"  ✓ Success ({len(description)} chars)\")\n",
    "            else:\n",
    "                storage.update_job_description(job_id, \"ERROR\")\n",
    "                print(f\"  ✗ Failed to extract description\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            storage.update_job_description(job_id, \"ERROR\")\n",
    "            print(f\"  ✗ Error: {e}\")\n",
    "        \n",
    "        # Sleep between requests to be polite\n",
    "        if i < total:\n",
    "            time.sleep(delay)\n",
    "    \n",
    "    print(f\"\\nCompleted: {successful}/{total} descriptions fetched successfully\")\n",
    "    return successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_multiple_pages(job_title, location, time_filter=None, limit=25):\n",
    "    \"\"\"\n",
    "    Scrape multiple pages of LinkedIn jobs.\n",
    "    \n",
    "    Args:\n",
    "        job_title: Job title to search\n",
    "        location: Location to search\n",
    "        time_filter: Not implemented yet (placeholder)\n",
    "        limit: Maximum number of jobs to fetch\n",
    "    \n",
    "    Returns:\n",
    "        List of job dictionaries (without descriptions)\n",
    "    \"\"\"\n",
    "    all_jobs = []\n",
    "    start = 0\n",
    "    \n",
    "    while len(all_jobs) < limit:\n",
    "        url = build_linkedin_search_url(job_title, location, start)\n",
    "        \n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "            \"Referer\": \"https://www.linkedin.com/\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                jobs = parse_job_cards(response.text)\n",
    "                \n",
    "                if not jobs:\n",
    "                    # No more jobs found\n",
    "                    break\n",
    "                \n",
    "                all_jobs.extend(jobs)\n",
    "                \n",
    "                # Stop if we've reached the limit\n",
    "                if len(all_jobs) >= limit:\n",
    "                    all_jobs = all_jobs[:limit]\n",
    "                    break\n",
    "                \n",
    "                start += 25\n",
    "                time.sleep(2)  # Be polite between page requests\n",
    "            else:\n",
    "                print(f\"Failed to fetch page at start={start}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching page: {e}\")\n",
    "            break\n",
    "    \n",
    "    return all_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_with_storage(job_title, location, time_filter=None, limit=25):\n",
    "    \"\"\"\n",
    "    Main workflow: Scrape jobs and fetch descriptions using storage.\n",
    "    \n",
    "    Args:\n",
    "        job_title: Job title to search\n",
    "        location: Location to search\n",
    "        time_filter: Time filter (not implemented)\n",
    "        limit: Maximum number of jobs to fetch\n",
    "    \n",
    "    Returns:\n",
    "        List of all jobs with descriptions\n",
    "    \"\"\"\n",
    "    # Initialize storage\n",
    "    storage = JobStorage()\n",
    "    \n",
    "    print(f\"Scraping {limit} jobs for '{job_title}' in '{location}'...\\n\")\n",
    "    \n",
    "    # Scrape job cards (without descriptions)\n",
    "    jobs = scrape_multiple_pages(job_title, location, time_filter, limit)\n",
    "    \n",
    "    # Add to storage\n",
    "    storage.add_jobs(jobs)\n",
    "    \n",
    "    # Print initial stats\n",
    "    stats = storage.get_stats()\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Found {stats['total_jobs']} jobs, fetching descriptions...\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Fetch all descriptions\n",
    "    fetch_all_descriptions(storage, delay=2)\n",
    "    \n",
    "    # Print final stats\n",
    "    final_stats = storage.get_stats()\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Final Statistics:\")\n",
    "    print(f\"  Total jobs: {final_stats['total_jobs']}\")\n",
    "    print(f\"  With descriptions: {final_stats['jobs_with_descriptions']}\")\n",
    "    print(f\"  Without descriptions: {final_stats['jobs_without_descriptions']}\")\n",
    "    print(f\"  Errors: {final_stats['jobs_with_errors']}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return storage.get_all_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_id': None,\n",
       "  'job_title': 'Cientista de Dados Jr.',\n",
       "  'company': 'UOL',\n",
       "  'location': 'São Paulo, São Paulo, Brazil',\n",
       "  'posted_ago': '1 day ago',\n",
       "  'job_url': 'https://br.linkedin.com/jobs/view/cientista-de-dados-jr-at-uol-4313390052?position=1&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=fof3H7h20H28X2NouS1CMQ%3D%3D',\n",
       "  'description': 'ERROR'},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientists - All Levels',\n",
       "  'company': 'Lensa',\n",
       "  'location': 'Boca Raton, FL',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientists-all-levels-at-lensa-4305439528?position=2&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=lDuRzruehWCxUFgNxyoKxw%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist, Data & Analytics – Customer, Loyalty & Marketing',\n",
       "  'company': 'Circle K',\n",
       "  'location': 'Charlotte, NC',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-data-analytics-%E2%80%93-customer-loyalty-marketing-at-circle-k-4316137579?position=3&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=e7ttQbzq7BbhInMHOSbbYA%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist (L5) - Ads (Forecasting)',\n",
       "  'company': 'Netflix',\n",
       "  'location': 'United States',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-l5-ads-forecasting-at-netflix-4246037078?position=4&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=5FbYTKpRfdgGP25DlGa1Tg%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Research Scientist, Mathematical Sciences',\n",
       "  'company': 'OpenAI',\n",
       "  'location': 'San Francisco, CA',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/research-scientist-mathematical-sciences-at-openai-4305400252?position=5&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=N%2FqO8%2FPyHQJ8MWhLyeGUrA%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'CIENTISTA DE DADOS PLENO (100% REMOTO)',\n",
       "  'company': 'ClearSale',\n",
       "  'location': 'Brazil',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://br.linkedin.com/jobs/view/cientista-de-dados-pleno-100%25-remoto-at-clearsale-4313833921?position=6&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=NuGwcA%2FUkOTAaqGlAd85Dg%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Junior Data Scientist – New Grad',\n",
       "  'company': 'PepsiCo',\n",
       "  'location': 'Mississauga, Ontario, Canada',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://ca.linkedin.com/jobs/view/junior-data-scientist-%E2%80%93-new-grad-at-pepsico-4313838496?position=7&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=1q3WbAJ0sOG%2BpnldW7eTYA%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Associate Software Engineer -Python/AI/ML',\n",
       "  'company': 'Devsinc',\n",
       "  'location': 'Lahore, Punjab, Pakistan',\n",
       "  'posted_ago': '1 day ago',\n",
       "  'job_url': 'https://pk.linkedin.com/jobs/view/associate-software-engineer-python-ai-ml-at-devsinc-4316354350?position=8&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=2Hu8j2QH17u1pOcMDdTRhw%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Python (AI/ML) Developer',\n",
       "  'company': 'Infosys',\n",
       "  'location': 'Bengaluru East, Karnataka, India',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://in.linkedin.com/jobs/view/python-ai-ml-developer-at-infosys-4316126291?position=9&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=rzVTpezovUDrBNuPuT3f5A%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist Intern',\n",
       "  'company': 'Lensa',\n",
       "  'location': 'United States',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-intern-at-lensa-4316574392?position=10&pageNum=0&refId=eL61fpBYTSOC3wKoUqnKqA%3D%3D&trackingId=3S%2Ba%2FOR0y%2B5nN3F00hkdFQ%3D%3D',\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing JobStorage with 10 Data Scientist jobs...\n",
      "\n",
      "Scraping 10 jobs for 'Data Scientist' in 'remote'...\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Found 10 jobs, fetching descriptions...\n",
      "================================================================================\n",
      "\n",
      "Fetching descriptions for 10 jobs...\n",
      "\n",
      "[1/10] Fetching description for: Cientista de Dados Jr....\n",
      "  ✗ Failed to extract description\n",
      "[2/10] Fetching description for: Data Scientists - All Levels...\n",
      "  ✗ Failed to extract description\n",
      "[3/10] Fetching description for: Data Scientist, Data & Analytics – Customer, Loyalty & Marketing...\n",
      "  ✗ Failed to extract description\n",
      "[4/10] Fetching description for: Data Scientist (L5) - Ads (Forecasting)...\n",
      "  ✗ Failed to extract description\n",
      "[5/10] Fetching description for: Research Scientist, Mathematical Sciences...\n",
      "  ✗ Failed to extract description\n",
      "[6/10] Fetching description for: CIENTISTA DE DADOS PLENO (100% REMOTO)...\n",
      "  ✗ Failed to extract description\n",
      "[7/10] Fetching description for: Junior Data Scientist – New Grad...\n",
      "  ✗ Failed to extract description\n",
      "[8/10] Fetching description for: Associate Software Engineer -Python/AI/ML...\n",
      "  ✗ Failed to extract description\n",
      "[9/10] Fetching description for: Python (AI/ML) Developer...\n",
      "  ✗ Failed to extract description\n",
      "[10/10] Fetching description for: Data Scientist Intern...\n",
      "  ✗ Failed to extract description\n",
      "\n",
      "Completed: 0/10 descriptions fetched successfully\n",
      "\n",
      "================================================================================\n",
      "Final Statistics:\n",
      "  Total jobs: 10\n",
      "  With descriptions: 0\n",
      "  Without descriptions: 9\n",
      "  Errors: 1\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Verification:\n",
      "✓ Total jobs returned: 10\n",
      "✓ Jobs with descriptions: 0\n",
      "✓ Jobs with errors: 1\n",
      "\n",
      "================================================================================\n",
      "Sample Job (first one):\n",
      "================================================================================\n",
      "Title: Cientista de Dados Jr.\n",
      "Company: UOL\n",
      "Location: São Paulo, São Paulo, Brazil\n",
      "Posted: 1 day ago\n",
      "Job ID: None\n",
      "Description: ERROR\n"
     ]
    }
   ],
   "source": [
    "# Test: Scrape 10 jobs with descriptions\n",
    "print(\"Testing JobStorage with 10 Data Scientist jobs...\\n\")\n",
    "\n",
    "# Test the complete workflow\n",
    "jobs = scrape_with_storage(\"Data Scientist\", \"remote\", \"past week\", 10)\n",
    "\n",
    "# Verify results\n",
    "print(\"\\nVerification:\")\n",
    "print(f\"✓ Total jobs returned: {len(jobs)}\")\n",
    "\n",
    "jobs_with_desc = sum(1 for j in jobs if j.get('description') and j['description'] != \"ERROR\")\n",
    "print(f\"✓ Jobs with descriptions: {jobs_with_desc}\")\n",
    "\n",
    "jobs_with_errors = sum(1 for j in jobs if j.get('description') == \"ERROR\")\n",
    "print(f\"✓ Jobs with errors: {jobs_with_errors}\")\n",
    "\n",
    "# Show sample job\n",
    "if jobs:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Sample Job (first one):\")\n",
    "    print(f\"{'='*80}\")\n",
    "    sample = jobs[0]\n",
    "    print(f\"Title: {sample['job_title']}\")\n",
    "    print(f\"Company: {sample['company']}\")\n",
    "    print(f\"Location: {sample['location']}\")\n",
    "    print(f\"Posted: {sample['posted_ago']}\")\n",
    "    print(f\"Job ID: {sample['job_id']}\")\n",
    "    \n",
    "    desc = sample.get('description', 'N/A')\n",
    "    if desc and desc != \"ERROR\":\n",
    "        desc_preview = desc[:200] + \"...\" if len(desc) > 200 else desc\n",
    "        print(f\"Description preview: {desc_preview}\")\n",
    "    else:\n",
    "        print(f\"Description: {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_id': None,\n",
       "  'job_title': 'Cientista de Dados Jr.',\n",
       "  'company': 'UOL',\n",
       "  'location': 'São Paulo, São Paulo, Brazil',\n",
       "  'posted_ago': '1 day ago',\n",
       "  'job_url': 'https://br.linkedin.com/jobs/view/cientista-de-dados-jr-at-uol-4313390052?position=1&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=uIGPqRmKL2Zp%2BrRfYZhLww%3D%3D',\n",
       "  'description': 'ERROR'},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientists - All Levels',\n",
       "  'company': 'Lensa',\n",
       "  'location': 'Boca Raton, FL',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientists-all-levels-at-lensa-4305439528?position=2&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=j1JAMe1oKfIazQ%2Fz%2FohwGg%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist, Data & Analytics – Customer, Loyalty & Marketing',\n",
       "  'company': 'Circle K',\n",
       "  'location': 'Charlotte, NC',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-data-analytics-%E2%80%93-customer-loyalty-marketing-at-circle-k-4316137579?position=3&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=brKmbAor271tMuHOwExs2Q%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist (L5) - Ads (Forecasting)',\n",
       "  'company': 'Netflix',\n",
       "  'location': 'United States',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-l5-ads-forecasting-at-netflix-4246037078?position=4&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=VpZShpGr9Q9UY%2BaBdVrunQ%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Research Scientist, Mathematical Sciences',\n",
       "  'company': 'OpenAI',\n",
       "  'location': 'San Francisco, CA',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/research-scientist-mathematical-sciences-at-openai-4305400252?position=5&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=nr4KKHryxiwI%2FEpoZv%2BSeQ%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'CIENTISTA DE DADOS PLENO (100% REMOTO)',\n",
       "  'company': 'ClearSale',\n",
       "  'location': 'Brazil',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://br.linkedin.com/jobs/view/cientista-de-dados-pleno-100%25-remoto-at-clearsale-4313833921?position=6&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=J1gfCxo6b6kteECXZnZkfQ%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Junior Data Scientist – New Grad',\n",
       "  'company': 'PepsiCo',\n",
       "  'location': 'Mississauga, Ontario, Canada',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://ca.linkedin.com/jobs/view/junior-data-scientist-%E2%80%93-new-grad-at-pepsico-4313838496?position=7&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=1fexOxsFbjL6%2FLp6n9EaBw%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Associate Software Engineer -Python/AI/ML',\n",
       "  'company': 'Devsinc',\n",
       "  'location': 'Lahore, Punjab, Pakistan',\n",
       "  'posted_ago': '1 day ago',\n",
       "  'job_url': 'https://pk.linkedin.com/jobs/view/associate-software-engineer-python-ai-ml-at-devsinc-4316354350?position=8&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=x713V2IYal4cc2MHGjG4Rg%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Python (AI/ML) Developer',\n",
       "  'company': 'Infosys',\n",
       "  'location': 'Bengaluru East, Karnataka, India',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://in.linkedin.com/jobs/view/python-ai-ml-developer-at-infosys-4316126291?position=9&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=An6JUHy4jeYm%2BqTSlUU8PQ%3D%3D',\n",
       "  'description': None},\n",
       " {'job_id': None,\n",
       "  'job_title': 'Data Scientist Intern',\n",
       "  'company': 'Lensa',\n",
       "  'location': 'United States',\n",
       "  'posted_ago': 'N/A',\n",
       "  'job_url': 'https://www.linkedin.com/jobs/view/data-scientist-intern-at-lensa-4316574392?position=10&pageNum=0&refId=r8vm%2BrG%2B0ZTbNredBK8TzQ%3D%3D&trackingId=F9CnnveURSMD8XSsEVa8TA%3D%3D',\n",
       "  'description': None}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISR 3.8",
   "language": "python",
   "name": "isr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
